# Multi-LLM Configuration Management System

## ✅ Backend Implementation Status

### Completed:
- ✅ Fixed SecretStr serialization bug
- ✅ Created database migration (with UUID fix)
- ✅ Implemented encryption service
- ✅ Created LLMConfiguration model
- ✅ Implemented LLMConfigurationService
- ✅ Created all API endpoints
- ✅ Integrated routes into app

### Remaining:
- ⏳ Frontend components
- ⏳ Settings page update
- ⏳ State management
- ⏳ Tests

## 🎯 Problem Statement

Currently, OpenHands has significant limitations with LLM configuration:
1. **Only ONE LLM configuration** can be stored at a time
2. **API keys are stored as asterisks** (`**********`) due to SecretStr serialization bug
3. **Users must re-enter API keys** every time they switch providers
4. **No way to quickly test** different LLM providers
5. **Poor UX** - users lose their keys when saving settings

### Current Bug Details:
- When saving settings, `settings.model_dump()` converts SecretStr to asterisks
- The asterisks are then saved to the database, permanently losing the actual API key
- Test button fails because it tries to use `**********` as the actual API key
- Users see "Invalid API key" errors even with valid keys

## 🏗️ Proposed Architecture

### 1. Database Schema - New `llm_configurations` table:

```sql
CREATE TABLE llm_configurations (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    name VARCHAR(255) NOT NULL,  -- "My GPT-4 Key", "Work Claude", etc.
    provider VARCHAR(50) NOT NULL,  -- openai, anthropic, gemini, openrouter
    model VARCHAR(255) NOT NULL,  -- gpt-4o, claude-3.5-sonnet, etc.
    api_key_encrypted TEXT NOT NULL,  -- AES-256 encrypted
    base_url VARCHAR(500),  -- Optional custom endpoint
    is_default BOOLEAN DEFAULT FALSE,
    is_active BOOLEAN DEFAULT TRUE,
    last_used_at TIMESTAMP WITH TIME ZONE,
    test_status VARCHAR(50),  -- success, failed, untested
    test_message TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),

    -- Constraints
    CONSTRAINT unique_user_default UNIQUE (user_id, is_default) WHERE is_default = TRUE,
    INDEX idx_llm_configs_user_id (user_id),
    INDEX idx_llm_configs_provider (provider)
);
```

### 2. Backend Implementation Details

#### a) Fix SecretStr Serialization Issue:

**Option 1 - Quick Fix (settings.py:72):**
```python
# Instead of:
settings_dict = settings.model_dump(exclude_none=True)

# Use:
settings_dict = settings.model_dump(
    exclude_none=True,
    context={'expose_secrets': True}  # This prevents masking
)
```

**Option 2 - Better Solution:**
- Create custom `EncryptedField` type that stores encrypted values
- Use application-level encryption (AES-256) with key rotation
- Never use SecretStr for database storage

#### b) New API Endpoints:

```
GET    /api/llm-configurations
       Response: [{id, name, provider, model, is_default, test_status}]

POST   /api/llm-configurations
       Body: {name, provider, model, api_key, base_url?}

GET    /api/llm-configurations/{id}
       Response: {id, name, provider, model, base_url, api_key: "AIza...****"}

PUT    /api/llm-configurations/{id}
       Body: {name?, model?, api_key?, base_url?}

DELETE /api/llm-configurations/{id}

PUT    /api/llm-configurations/{id}/set-default

POST   /api/llm-configurations/test
       Body: {provider, model, api_key, base_url?}
       Response: {success: bool, message: string, latency?: number}
```

#### c) Service Layer (`llm_configuration_service.py`):

```python
class LLMConfigurationService:
    async def create_configuration(self, user_id: str, data: dict) -> LLMConfiguration:
        # Encrypt API key before storing
        encrypted_key = await self.encrypt_api_key(data['api_key'])
        # Ensure only one default per user
        if data.get('is_default'):
            await self.clear_default_for_user(user_id)

    async def test_configuration(self, config: LLMConfiguration) -> TestResult:
        # Decrypt key, create LLM instance, test with simple prompt
        decrypted_key = await self.decrypt_api_key(config.api_key_encrypted)
        llm = LLM(LLMConfig(
            model=config.model,
            api_key=decrypted_key,
            base_url=config.base_url
        ))
        # Test with minimal tokens
        response = await llm.acompletion(
            messages=[{"role": "user", "content": "Hi"}],
            max_tokens=5
        )
```

### 3. Frontend Implementation

#### a) New Routes & Pages:

**`/settings/llm-configurations`** - Management Page
- Table view with columns: Name, Provider, Model, Status, Actions
- Bulk actions: Delete selected, Test all
- Search/filter by provider
- Quick stats: Total configs, Active, Failed tests

**Updated `/settings/llm`** - Settings Page
- Dropdown to select active configuration
- "Manage Configurations" link
- Real-time test status indicator
- Show partial API key (first 4 + last 4 chars)

#### b) React Components:

```typescript
// LLMConfigurationSelector.tsx
interface LLMConfig {
  id: string;
  name: string;
  provider: string;
  model: string;
  isDefault: boolean;
  testStatus: 'success' | 'failed' | 'untested';
}

// ConfigurationTestButton.tsx
- Shows loading spinner during test
- Green check or red X based on result
- Tooltip with error details if failed

// AddConfigurationModal.tsx
- Provider dropdown (with logos)
- Model dropdown (filtered by provider)
- API key input with show/hide toggle
- Auto-test on save option
```

#### c) State Management:

```typescript
// Redux slice: llmConfigSlice.ts
interface LLMConfigState {
  configurations: LLMConfig[];
  activeConfigId: string | null;
  isLoading: boolean;
  testResults: Record<string, TestResult>;
}

// Per-conversation config override
interface ConversationState {
  // ... existing fields
  llmConfigId?: string;  // Override default
}
```

### 4. Migration Strategy

#### Phase 1: Database Migration
```sql
-- 1. Create new table
CREATE TABLE llm_configurations ...

-- 2. Migrate existing settings
INSERT INTO llm_configurations (user_id, name, provider, model, api_key_encrypted, is_default)
SELECT
    u.id,
    'Migrated Configuration',
    SPLIT_PART(s.settings->>'llm_model', '/', 1) as provider,
    s.settings->>'llm_model',
    encrypt(s.settings->>'llm_api_key', :encryption_key),
    TRUE
FROM users u
JOIN user_settings s ON u.id = s.user_id
WHERE s.settings->>'llm_api_key' IS NOT NULL
  AND s.settings->>'llm_api_key' != '**********';
```

#### Phase 2: Backward Compatibility
- Keep reading from old settings for 30 days
- Write to both old and new tables during transition
- Show migration prompt to users with old configs

### 5. Security Considerations

#### API Key Encryption:
```python
# Using cryptography library
from cryptography.fernet import Fernet

class APIKeyEncryption:
    def __init__(self, key: str):
        self.cipher = Fernet(key.encode())

    def encrypt(self, api_key: str) -> str:
        return self.cipher.encrypt(api_key.encode()).decode()

    def decrypt(self, encrypted: str) -> str:
        return self.cipher.decrypt(encrypted.encode()).decode()
```

#### Key Rotation:
- Store key version with encrypted data
- Support multiple decryption keys
- Background job to re-encrypt with new key

#### API Response Security:
```python
def mask_api_key(api_key: str) -> str:
    if len(api_key) <= 8:
        return "****"
    return f"{api_key[:4]}...{api_key[-4:]}"
```

### 6. User Experience Improvements

#### Quick Switch Dropdown (in conversation header):
```
[🤖 GPT-4 ▼] [💬 New Chat] [⚙️ Settings]
    ├── 🧠 Claude 3.5 (default)
    ├── 🤖 GPT-4
    ├── 🔷 Gemini Pro
    └── ➕ Add New Configuration
```

#### Test Results Display:
- ✅ **Success**: "LLM responding correctly (120ms)"
- ❌ **Failed**: "Invalid API key - please check your key"
- ⚠️ **Rate Limited**: "Rate limit exceeded - try again in 5s"
- 🔄 **Testing**: "Validating configuration..."

### 7. Implementation Timeline

**Week 1**: Backend Foundation
- Day 1-2: Create migration, implement encryption
- Day 3-4: Build API endpoints and service layer
- Day 5: Testing and security review

**Week 2**: Frontend Development
- Day 1-2: Configuration management page
- Day 3-4: Update settings page and selector
- Day 5: Integration testing

**Week 3**: Polish & Migration
- Day 1-2: Data migration scripts
- Day 3-4: Documentation and user guides
- Day 5: Staged rollout

### 8. Success Metrics

- **API Key Retention**: 100% (no more lost keys)
- **Configuration Switching**: < 2 clicks
- **Test Latency**: < 2 seconds per config
- **User Adoption**: 80% using multiple configs within 30 days

### 9. Future Enhancements

1. **Configuration Templates**: Pre-configured setups for common use cases
2. **Team Sharing**: Share configurations within teams (keys encrypted per team)
3. **Usage Analytics**: Track token usage per configuration
4. **Cost Tracking**: Monitor spending per API key
5. **Auto-Switching**: Fallback to another config if primary fails
6. **Configuration Import/Export**: JSON format for backup/sharing

---

## 🚨 Immediate Action Items

1. **HOTFIX**: Fix SecretStr serialization to stop losing API keys
2. **Create Jira/GitHub Issues** for each implementation phase
3. **Security Review**: Get encryption approach approved
4. **UX Mockups**: Design configuration management UI
5. **Database Backup**: Before running migration scripts



## Thought Process

📝 Enhanced Documentation Includes:

  1. Detailed Problem Statement

  - Clear explanation of the current bugs (API keys stored as
   asterisks)
  - Specific pain points users are experiencing
  - Technical root cause analysis

  2. Complete Database Schema

  - Full SQL table definition with proper constraints
  - Indexes for performance
  - Unique constraint to ensure only one default per user

  3. Implementation Details

  - Two options for fixing the SecretStr bug (quick fix vs.
  proper solution)
  - Complete API endpoint specifications with
  request/response formats
  - Service layer code examples
  - Encryption implementation with code samples

  4. Frontend Architecture

  - Specific component designs
  - TypeScript interfaces
  - State management approach
  - UI/UX mockups in text format

  5. Security Deep Dive

  - API key encryption using industry-standard AES-256
  - Key rotation strategy
  - API response masking (showing only first/last 4 chars)

  6. Migration Strategy

  - SQL migration scripts
  - Backward compatibility plan
  - Data migration from existing system

  7. User Experience Details

  - Quick switch dropdown mockup
  - Test result states with emojis
  - Error messaging guidelines

  8. Project Management

  - 3-week implementation timeline
  - Success metrics to track
  - Immediate action items
  - Future enhancement roadmap

  This documentation can now serve as a complete technical
  specification that any developer can use to implement the
  feature. It addresses all the pain points you mentioned and
   provides a clear path forward to give users a much better
  experience with LLM configuration management.
